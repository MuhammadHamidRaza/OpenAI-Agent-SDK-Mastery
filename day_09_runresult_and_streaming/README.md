# Day 9: `RunResult` and Streaming

[![Proprietary License](https://img.shields.io/badge/license-proprietary-red.svg)](../LICENSE)

---

### **Course Overview**

Welcome to Day 9 of the **OpenAI Agent SDK Mastery** course! We've explored how agents think, act, and remember. Today, we focus on understanding the *outcome* of an agent's execution and how to enhance the user experience by providing real-time feedback. We'll dive deep into the `RunResult` object, which encapsulates all the details of an agent's run, and then explore **streaming**, a powerful technique to deliver partial outputs as they are generated, making your agent applications feel more responsive and dynamic. This session will equip you with the knowledge to inspect agent behavior and build more engaging user interfaces.

---

## Understanding the `RunResult` Object

Whenever you execute an agent using `Runner.run()`, `Runner.run_sync()`, or `Runner.run_streamed()`, the primary output is a `RunResult` object (or `RunResultStreaming` for streamed runs, which inherits from `RunResultBase`). This object is a comprehensive container for everything that happened during the agent's execution. It's your window into the agent's thought process, tool usage, and final outcome.

Inspecting the `RunResult` is crucial for debugging, understanding agent behavior, and extracting the final answer or any intermediate steps.

### Key Properties of `RunResult` (and `RunResultStreaming`):

*   **`final_output`**: This is the most commonly used property, containing the agent's ultimate answer or the final output of the run. It's typically a string, but can be an object if a specific `output_type` was defined for the agent.
*   **`new_items`**: A chronological list of `RunItem` objects that represent every significant event during the agent's execution. This includes:
    *   `MessageOutputItem`: Messages generated by the LLM.
    *   `ToolCallItem`: An indication that the LLM requested a tool to be called.
    *   `ToolCallOutputItem`: The output received from a tool after its execution.
    *   `ReasoningItem`: Insights into the LLM's thought process (if enabled).
    *   `HandoffCallItem` / `HandoffOutputItem`: Related to multi-agent handoffs (covered later).
*   **`last_agent`**: The `Agent` instance that produced the `final_output`. Useful in multi-agent scenarios to know which agent completed the task.
*   **`input`**: The original input provided to the `run` method.
*   **`to_input_list()`**: A utility method that converts the run's history into a format suitable for continuing the conversation manually (without sessions).
*   **`raw_responses`**: Low-level `ModelResponses` from the LLM, containing token information and metadata.
*   **`input_guardrail_results` / `output_guardrail_results`**: Results from any guardrails applied to the input or output (covered later).

### Example: Inspecting `RunResult`

```python
from agents import Agent, Runner
from agents.tools import function_tool
import os

# Ensure the OpenAI API key is set
# os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY" 

if "OPENAI_API_KEY" not in os.environ:
    print("Please set the OPENAI_API_KEY environment variable.")
    exit()

@function_tool
def get_current_time(timezone: str = "UTC") -> str:
    """Returns the current time in a specified timezone.

    Args:
        timezone: The timezone to get the time for (e.g., "America/New_York", "UTC"). Defaults to "UTC".

    Returns:
        A string representing the current time.
    """
    from datetime import datetime
    import pytz
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz)
        return now.strftime("%Y-%m-%d %H:%M:%S %Z%z")
    except pytz.UnknownTimeZoneError:
        return f"Error: Unknown timezone '{timezone}'."

agent = Agent(
    name="TimeAgent",
    instructions="You are a helpful assistant that can tell the current time.",
    tools=[get_current_time]
)

print("Running TimeAgent...")
result = Runner.run_sync(agent, "What time is it in New York?")

print("\n--- RunResult Inspection ---")
print(f"Final Output: {result.final_output}")
print(f"Original Input: {result.input}")
print(f"Last Agent: {result.last_agent.name}")

print("\nNew Items (Chronological Events):")
for item in result.new_items:
    print(f"  - Type: {type(item).__name__}")
    if hasattr(item, 'text'):
        print(f"    Text: {item.text[:50]}...") # Print first 50 chars of text
    if hasattr(item, 'tool_name'):
        print(f"    Tool Called: {item.tool_name}")
        print(f"    Tool Args: {item.tool_args}")
    if hasattr(item, 'output'):
        print(f"    Tool Output: {item.output}")

```

---

## Implementing Streaming for Enhanced User Experience

While `RunResult` provides the complete picture after execution, waiting for the entire process to finish can lead to perceived latency, especially for complex tasks. **Streaming** allows you to receive partial outputs and events as they happen, providing real-time feedback to the user.

The `Runner.run_streamed()` method is designed for this purpose. Instead of returning a single `RunResult` at the end, it returns an iterable `RunResultStreaming` object that yields `RunItem` events as the agent progresses.

### When to Use Streaming:

*   **Chat Interfaces:** Displaying text token by token as the LLM generates it.
*   **Progress Indicators:** Showing tool calls, reasoning steps, or other intermediate events.
*   **Debugging:** Gaining real-time insight into the agent's execution flow.

### Example: Agent with Streaming Output

```python
from agents import Agent, Runner
import os

# Ensure the OpenAI API key is set
# os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY" 

if "OPENAI_API_KEY" not in os.environ:
    print("Please set the OPENAI_API_KEY environment variable.")
    exit()

agent = Agent(
    name="StreamingAssistant",
    instructions="You are a verbose assistant that explains concepts step-by-step."
)

print("Running StreamingAssistant with real-time output...")

# Use a 'with' statement for run_streamed to ensure proper resource management
with Runner.run_streamed(agent, "Explain the concept of photosynthesis in simple terms.") as stream:
    for event in stream:
        # Check the type of event to handle it appropriately
        if hasattr(event, 'text'):
            # This is a message from the LLM, print it as it comes
            print(event.text, end="", flush=True)
        elif hasattr(event, 'tool_name'):
            # An agent decided to call a tool
            print(f"\n[TOOL CALL: {event.tool_name} with args {event.tool_args}]\n", end="", flush=True)
        elif hasattr(event, 'output'):
            # Output from a tool call
            print(f"\n[TOOL OUTPUT: {event.output}]\n", end="", flush=True)
        # You can add more elif conditions for other RunItem types like ReasoningItem, HandoffCallItem etc.

    # After the loop, the stream is complete. You can get the final result.
    final_result = stream.get_final_result()
    print(f"\n\n--- Streaming Complete ---")
    print(f"Final Output (from get_final_result): {final_result.final_output[:100]}...") # Print first 100 chars

```

**Explanation:**

*   The `with Runner.run_streamed(...) as stream:` block ensures the stream is properly managed.
*   The `for event in stream:` loop iterates over the `RunItem` objects yielded by the stream.
*   By checking `hasattr(event, 'text')`, we can print the LLM's generated text as it arrives, creating a typewriter effect.
*   You can add logic to handle other `RunItem` types (like `ToolCallItem` or `ToolCallOutputItem`) to provide even richer real-time feedback.
*   `stream.get_final_result()` allows you to retrieve the complete `RunResult` object after the streaming is finished.

---

## Key Takeaways

*   The `RunResult` object is a comprehensive record of an agent's execution, providing insights into its `final_output`, `new_items` (events), and more.
*   `Runner.run_streamed()` enables real-time delivery of agent outputs and events, significantly improving user experience in interactive applications.
*   By combining `RunResult` inspection with streaming, you gain powerful capabilities for debugging, monitoring, and building dynamic agent interfaces.

Tomorrow, we'll build upon our understanding of agent execution by exploring **Tracing**, a powerful feature for visualizing and debugging your agent's workflow, giving you even deeper insights into its internal processes.